# Name the components on this agent
hdfs1.sources = r1
hdfs1.sinks = k1
hdfs1.channels = c1

# Describe/configure the source
hdfs1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
hdfs1.sources.r1.zookeeperConnect = cg1:2181,cg2:2181,cg3:2181,cg4:2181
hdfs1.sources.r1.kafka.bootstrap.servers = cg5:9092,cg2:9092,cg3:9092,cg4:9092
hdfs1.sources.r1.kafka.topics = w19
hdfs1.sources.r1.kafka.consumer.group.id = w19
hdfs1.sources.r1.kafka.consumer.client.id = w19
hdfs1.sources.r1.flumeBatchSize = 10000
hdfs1.sources.r1.kafka.consumer.timeout.ms = 100

# Describe the sink
hdfs1.sinks.k1.type = hdfs
hdfs1.sinks.k1.hdfs.path = hdfs://cg1/flume/weibo_content_day/20160519
hdfs1.sinks.k1.hdfs.filePrefix = flume
#hdfs1.sinks.k1.hdfs.fileSuffix = %Y%m%d%H%M%S
hdfs1.sinks.k1.hdfs.fileType = DataStream
#1G
hdfs1.sinks.k1.hdfs.rollSize = 268435456
hdfs1.sinks.k1.hdfs.rollInterval = 0
hdfs1.sinks.k1.hdfs.rollCount =0
hdfs1.sinks.k1.hdfs.batchSize = 10000
hdfs1.sinks.k1.hdfs.idleTimeout = 30
hdfs1.sinks.k1.hdfs.useLocalTimeStamp = true
hdfs1.sinks.k1.hdfs.maxOpenFiles = 100000000
hdfs1.sinks.k1.hdfs.callTimeout = 60000
#hdfs1.sinks.k1.hdfs.round = true
#hdfs1.sinks.k1.hdfs.roundValue = 10
#hdfs1.sinks.k1.hdfs.roundUnit = minute
hdfs1.sinks.k1.hdfs.codeC = lzo
hdfs1.sinks.k1.hdfs.fileType = CompressedStream



# Use a channel which buffers events in memory
#hdfs1.channels.c1.type = memory
#hdfs1.channels.c1.capacity = 1000000
#hdfs1.channels.c1.transactionCapacity = 5000
#hdfs1.channels.c1.byteCapacityBufferPercentage = 20
#hdfs1.channels.c1.byteCapacity = 800000000
#hdfs1.channels.c1.keep-alive = 60

hdfs1.channels.c1.type = file
hdfs1.channels.c1.checkpointDir = /home/flumedata/checkpoint
hdfs1.channels.c1.dataDirs = /home/flumedata/data
hdfs1.channels.c1.transactionCapacity = 10000
hdfs1.channels.c1.maxFileSize = 2146435071
hdfs1.channels.c1.capacity = 100000000
hdfs1.channels.c1.keep-alive = 120

# Bind the source and sink to the channel
hdfs1.sources.r1.channels = c1
hdfs1.sinks.k1.channel = c1
